replicaCount: 1

image:
  # Note: the name of the repository is used throughout the chart to figure if we should configure for SE or EE
  # "axoniq/axonserver" is the SE Docker image. Any other (custom) image means that the chart will configure for EE
  repository: axoniq/axonserver
  pullPolicy: IfNotPresent
  tag: "4.4"

config:
  serverDomain: nonprod.axon
  internalToken: ~

  # For the Axon Server security token and license, you can manage them with the chart or externally.
  # If you wish to manage them outside the chart, leave these two values to nil and set the existingSecrets' names
  token: ~
  license: ~
  # license: |
  #   #AxonIQ License File generated on 1970-01-01
  #   #Thu Jan 01 00:00:00 UTC 1970
  #   license_key_id=00000000-0000-0000-0000-000000000000
  #   signature=veryLongSignatureString
  #   ...
  #   product=AxonServer
  #   licensee=Croix Bleue
  #   clusterNodes=3
  existingSecrets: {}
  # tokenSecretName: some-secret
  # licenseSecretName: another-secret
  # # See the following example on how to create these secrets:
  # # https://github.com/AxonIQ/running-axon-server/blob/master/3-k8s/2-k8s-ee/create-secrets.sh#L23-L24

  # If propertiesFileData is nil, a default config file will be created
  propertiesFileData: ~
  # propertiesFileData: |
  #   axoniq.axonserver.devmode.enabled=true
  #   axoniq.axonserver.accesscontrol.enabled=true

  java:
    jvmOptions:
      additionnalOptions: ~
      # Depending on your memory configuration, you might want to raise or lower these percentages.
      # The more memory you assign, the higher the percentages can be.
      memoryOptions: "-XX:MinRAMPercentage=75 -XX:MaxRAMPercentage=85"
      # We suggests to crash and exit immediately on OOM errors so that Kubernetes will start a new and healthy container
      memoryErrorOptions: "-XX:+ExitOnOutOfMemoryError -XX:+CrashOnOutOfMemoryError"
      timezoneOptions: "-Duser.timezone=UTC"
      networkingOptions: "-Dnetworkaddress.cache.ttl=0 -Dnetworkaddress.cache.negative.ttl=0"

imagePullSecrets: []

serviceAccount:
  create: true
  annotations: {}

podAnnotations: {}

podSecurityContext:
  runAsUser: 1001
  fsGroup: 1001

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1001

services:
  gui:
    type: LoadBalancer
    port: 8024
  grpc:
    type: ClusterIP
    port: 8124
  internalGrpc:
    type: ClusterIP
    port: 8224

# This chart only exposes the GUI port through a k8s ingress
ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # nginx.ingress.kubernetes.io/affinity: cookie
    # nginx.ingress.kubernetes.io/affinity-mode: persistent
  # hosts:
  #  - host: chart-example.local
  #    paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

persistence:
  enabled: false
  # This chart can use the standard storage class, use an already existing custom class or create and use
  # a new custom class.
  #
  # The customStorageClass flag is used to have the chart create and manage a custom storage class
  # If customStorageClass is used, you need to defined other flags such as storageClass, storageProvisioner
  # and storageParameters
  #
  # customStorageClass: true
  #
  # Regardless of customStorageClass, storageClass can be provided for claims template to be created using that
  # storageClass. The parameters storageProvisioner and storageParameters are only used by the StorageClass manifest
  #
  # storageClassName: standard
  # storageProvisioner: kubernetes.io/aws-ebs
  # storageParameters:
  #   type: io1
  #   iopsPerGB: "10"
  #   fsType: ext4

  accessModes: [ReadWriteOnce]

  # Storage capacity for the 'data' directory, which is used to hold things such as the flow.xml.gz, configuration, state, etc.
  eventstoreStorage:
    size: 16Gi
  # Storage capacity for
  dataStorage:
    size: 3Gi

  logStorage:
    size: 3Gi

## Lifecycle handlers:
##   https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/
# postStart: "echo Hello from the postStart handler > /usr/share/message"
# preStop: "nginx -s quit; while killall -0 nginx; do sleep 1; done"

## Additional environment variables to set
extraEnvs: []
# extraEnvs:
#   - name: FOO
#     value: some-value
#   - name: BAR
#     valueFrom:
#       secretKeyRef:
#         key: FOO
#         name: secret-resource

extraVolumeMounts: []
## Additional volumeMounts to the main container.
#  - name: plugin-dir
#   mountPath: /var/lib/octant-plugins

extraVolumes: []
## Additional volumes to the pod.
#  - name: plugin-dir
#    emptyDir: {}

extraVolumeClaimTemplates: []
## Additional volumes claim templates.
#  - metadata:
#      name: some-claim-template
#    spec:
#      accessModes: [ "ReadWriteOnce" ]
#      resources:
#        requests:
#          storage: 2Gi

extraInitContainers: []
## Add init containers, which are run before Axon server is started.
# - name: init-myservice
#   image: busybox
#   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']

extraSidecarContainers: []
## Add sidecar containers to run along Axon server.
# - name: logger
#   image: ez123/alpine-tini

# Virtual service is Istio's set of traffic routing rules
# Istio 1.4+ is supported. For complex use case, consider leaving this to false
# and patching-in your own definition for VirtualService and other resources
virtualservices:
  enabled: false

  gui:
    gateways: []
    # - istio-system/my-istio-gateway
    hosts: []
    # - ui.axon.example.domain
  grpc:
    gateways: []
    # - istio-system/my-istio-gateway
    hosts: []
    # - grpc.axon.example.domain

  # Istio security rules:
  rules: []
  # # eg:
  # - from:
  #   - source:
  #      namespaces: ["istio-system"]
  #   to:
  #   - operation:
  #       ports:
  #       - "8024"
  #       - "8124"
  #  - from:
  #    - source:
  #        namespaces: ["axonserveree-nonprod"]
  #    to:
  #    - operation:
  #        ports:
  #        - "8024"
  #        - "8124"
  #        - "8224"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}
#   cloud.com/my-nodepool: axon-pool

tolerations: []

# By default, we suggest to run the Axon server EE instances on different Kubernetes nodes
# (no impact for SE)
# Note that if you install multiple Axon server EE, you could colocate different server's instances on the same
# host. In order to do this you should change the "values" key down there
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
        - key: app.kubernetes.io/instance
          operator: In
          values:
          - axonserver
      topologyKey: kubernetes.io/hostname
